run_name: tokenize-github_0pt9
platform: r1z1
gpu_type: a100_80gb
gpu_num: 8
image: mosaicml/examples:llm-latest
integrations:
- integration_type: git_repo
  git_repo: codestar12/examples
  git_branch: streaming_concat
command: |
  cd examples

  pip install awscli

  python examples/common/pretokenize_streaming_dataset.py --local /tmp/streaming_datasets/github --remote s3://mosaicml-internal-checkpoints-shared/matthew/github/keep_0pt9 --splits train --out_root /tmp/preconcat/0pt9 --compression zstd --concat_tokens 2048 --tokenizer gpt2 --eos_text '<|endoftext|>'
  
  aws s3 cp /tmp/preconcat s3://mosaicml-internal-checkpoints-shared/matthew/github/preconcat --recursive